{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "metadata": {}
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import CharRNN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating the data for training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "metadata": {}
   },
   "outputs": [],
   "source": [
    "# isolating the review column and saving it to a text file\n",
    "data = pd.read_csv('./data/Airline_Reviews.csv', encoding='utf-8')\n",
    "data = data['Review']\n",
    "data.to_csv('./data/reviews.txt', index=False, header=False, sep='\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "metadata": {}
   },
   "source": [
    "## Small tweaks to the code\n",
    "\n",
    "I changed the \"train()\" method to accept parameters, since we are gonna be varying some of them, also enabling the possibility to add dropout layers. I also added the progress bar, the plots, and added sporadic loss prints: since the training is very slow on RNNs, being able to look at the loss only after every epoch would not be enough. I also added the possibility to save loss vectors: I can load a saved model and continue training it, without losing the previous loss plot."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "metadata": {}
   },
   "outputs": [],
   "source": [
    "# let's try with a very simple model first\n",
    "\n",
    "CharRNN.train(num_layers=1, hidden_size=128, epochs = 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "metadata": {}
   },
   "outputs": [],
   "source": [
    "# Let's try with more parameters\n",
    "\n",
    "CharRNN.train(num_layers=2, hidden_size=256, epochs = 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CharRNN.train(num_layers=2, hidden_size=256, epochs = 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "metadata": {}
   },
   "outputs": [],
   "source": [
    "# these are the standard parameters put in the train function by the author, but he trains on a smaller corpus (3,6 MB vs 16 MB), so I expect\n",
    "# it to still not be enough\n",
    "\n",
    "CharRNN.train(num_layers=3, hidden_size=128, epochs = 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CharRNN.train(num_layers=3, hidden_size=256, epochs = 2, dropout = 0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "metadata": {}
   },
   "outputs": [],
   "source": [
    "CharRNN.train(num_layers=4, hidden_size=128, epochs=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CharRNN.train(num_layers=4, hidden_size=256, epochs=2, dropout = 0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CharRNN.train(num_layers=5, hidden_size=128, epochs=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CharRNN.train(num_layers=4, hidden_size=256, epochs=2, dropout = 0.1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
